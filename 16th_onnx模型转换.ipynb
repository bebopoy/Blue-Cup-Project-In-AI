{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX 模型转换\n",
    "在上节实验中，我们介绍了如何使用 ONNX 来加载模型，并可视化其内部结构。在本次实验中，我们将进一步探讨如何将 Pytorch 模型转换为 ONNX 格式，并在此过程中解决可能遇到的复杂问题。\n",
    "\n",
    "知识点\n",
    "Pytorch 模型转换\n",
    "转换检查\n",
    "动态操作支持\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们先使用 Pytorch 定义一个经典的图像分类模型，包括卷积层、全连接层、激活函数，以及批归一化层。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型转换\n",
    "Pytorch 模型转换为 ONNX 格式的过程中，可以使用多种方法来进行转换。\n",
    "\n",
    "#### 使用 torch.onnx.export\n",
    "torch.onnx.export 是最常用的 Pytorch 模型转换方法，适合大多数场景。它支持多种输入输出格式、动态轴、和不同导出设置。\n",
    "\n",
    "以下是最简单的使用方法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "\n",
    "# 创建模型实例\n",
    "model = Model()\n",
    "dummy_input = torch.randn(1, 1, 28, 28)\n",
    "\n",
    "# 基础转换\n",
    "torch.onnx.export(model, dummy_input, \"model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ model：需要转换的 Pytorch 模型实例。\n",
    "+ dummy_input：用于模型的输入张量，用来追踪模型的计算图。\n",
    "+ \"model.onnx\"：导出的 ONNX 模型的保存路径。\n",
    "\n",
    "扩展用法\n",
    "此外，我们还可以增加参数来应对更加复杂的场景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"model_2.onnx\",\n",
    "    export_params=True,  # 默认 True, 导出模型参数。\n",
    "    opset_version=11,  # ONNX opset 版本，默认为 11，支持最新的 ONNX 操作。\n",
    "    do_constant_folding=True,  # 是否执行常量折叠优化。\n",
    "    input_names=['input'],  # 输入的名称，用于标识输入节点。\n",
    "    output_names=['output'],  # 输出的名称，用于标识输出节点。\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}},  # 动态轴设置，允许动态的 batch size。\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ export_params：控制是否导出模型参数。当设置为 False 时，只导出模型结构，而不包含权重。\n",
    "+ opset_version：指定导出使用的 ONNX opset 版本，确保与运行环境的兼容性。\n",
    "+ do_constant_folding：启用常量折叠优化，减少模型中的计算冗余。\n",
    "+ input_names 和 output_names：定义输入和输出节点的名称，方便在 ONNX 模型中查找。\n",
    "+ dynamic_axes：定义动态轴，这对于处理可变大小的输入（如 batch size，图像分割任务不限制图像尺寸等）非常有用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转换检查\n",
    "转换完成后，我们可以使用 ONNX 的 onnx.checker 来验证模型的有效性，确保模型在转换过程中没有出现错误。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "# 加载 ONNX 模型\n",
    "onnx_model = onnx.load(\"model.onnx\")\n",
    "\n",
    "# 检查模型\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 onnx.checker.check_model 检查 ONNX 模型时，如果模型正确，通常不会有任何输出。然而，如果模型存在错误或不一致性， check_model 会抛出一个 onnx.checker.ValidationError 异常，详细描述模型中的问题，如：\n",
    "\n",
    "+ 图结构错误：节点的输入或输出不存在、存在循环依赖、节点的拓扑排序错误。\n",
    "+ 数据类型不匹配：输入和输出之间的数据类型不一致、某个节点的输入数据类型与其操作不兼容。\n",
    "+ 形状不匹配：节点的输入和输出的张量形状不匹配、某些操作（如矩阵乘法）要求特定形状，但输入张量不满足这些要求。\n",
    "+ 不支持的操作：模型中包含不支持的或无效的操作符、操作符的属性配置错误。\n",
    "+ 未定义的节点：模型中引用了未定义的节点或操作符。\n",
    "+ 未定义的输入/输出：模型的输入或输出在模型中未正确定义。\n",
    "+ 未能遵循 ONNX 标准：模型不符合 ONNX 规范，例如版本不一致、属性缺失等。\n",
    "\n",
    "\n",
    "当 onnx.checker.check_model 发现这些问题时，它会抛出异常，并附带详细的错误信息，帮助开发者定位和修复问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.onnx.export 的局限性\n",
    "torch.onnx.export 方法是直接将模型从 Pytorch 转换为 ONNX 格式的主要方式，适用于大多数情况。然而，当模型包含一些动态行为或复杂的自定义操作时，方法 1 可能面临以下挑战：\n",
    "\n",
    "+ 动态计算图：torch.onnx.export 默认的导出是基于一次前向传播过程（forward pass）捕获的计算图。这种静态追踪方法对大多数简单模型都有效，但对于包含动态分支或条件语句的模型，静态追踪可能会遗漏或错误处理某些路径，导致转换的模型不完整或不正确。\n",
    "+ 自定义操作：某些 Pytorch 模型可能包含自定义操作，这些操作在 ONNX 的标准操作集中不存在。torch.onnx.export的基础导出无法处理这些自定义操作，可能会导致转换失败或生成不符合预期的 ONNX 模型。\n",
    "\n",
    "接下来，我们将进一步学习动态计算图的导出方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 torch.jit.script 与 torch.onnx.export\n",
    "当模型包含一些动态操作时，如下定义的模型， forward 函数中包含一个条件判断，如果输入 x 的第一个元素大于 0，则执行 x = x * 2 操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BranchModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BranchModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 20)\n",
    "        self.fc2 = nn.Linear(20, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        # 条件分支：当输入 x 的第一个元素大于 0 时，乘以 2\n",
    "        if x[0, 0] > 0:\n",
    "            x = x * 2\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们直接使用前面的 torch.onnx.export 进行导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_651/1502988478.py:10: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x[0, 0] > 0:\n"
     ]
    }
   ],
   "source": [
    "branch_model = BranchModel()\n",
    "dummy_input = torch.randn(1, 10)\n",
    "torch.onnx.export(branch_model, dummy_input, \"branch_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里就已经报了一个 TracerWarning ，再用上一节实验的方法，打印模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node name: /fc1/Gemm\n",
      "Node operation: Gemm\n",
      "Node inputs: ['onnx::Gemm_0', 'fc1.weight', 'fc1.bias']\n",
      "Node outputs: ['/fc1/Gemm_output_0']\n",
      "\n",
      "\n",
      "Node name: /Relu\n",
      "Node operation: Relu\n",
      "Node inputs: ['/fc1/Gemm_output_0']\n",
      "Node outputs: ['/Relu_output_0']\n",
      "\n",
      "\n",
      "Node name: /fc2/Gemm\n",
      "Node operation: Gemm\n",
      "Node inputs: ['/Relu_output_0', 'fc2.weight', 'fc2.bias']\n",
      "Node outputs: ['7']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = onnx.load(\"branch_model.onnx\")\n",
    "for node in model.graph.node:\n",
    "    print(f\"Node name: {node.name}\")  # 节点名称\n",
    "    print(f\"Node operation: {node.op_type}\")  # 节点操作类型\n",
    "    print(f\"Node inputs: {node.input}\")  # 节点输入\n",
    "    print(f\"Node outputs: {node.output}\")  # 节点输出\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到只有三个节点，分别是全连接、激活、全连接。\n",
    "\n",
    "我们再使用 torch.jit.script 进行追踪，以生成更精确的计算图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 通过 torch.jit.trace 进行追踪\n",
    "traced_model = torch.jit.script(branch_model)\n",
    "\n",
    "# 导出为 ONNX\n",
    "torch.onnx.export(traced_model, dummy_input, \"traced_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样打印模型信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node name: /Constant\n",
      "Node operation: Constant\n",
      "Node inputs: []\n",
      "Node outputs: ['/Constant_output_0']\n",
      "\n",
      "\n",
      "Node name: /fc1/Gemm\n",
      "Node operation: Gemm\n",
      "Node inputs: ['x.1', 'fc1.weight', 'fc1.bias']\n",
      "Node outputs: ['/fc1/Gemm_output_0']\n",
      "\n",
      "\n",
      "Node name: /Relu\n",
      "Node operation: Relu\n",
      "Node inputs: ['/fc1/Gemm_output_0']\n",
      "Node outputs: ['/Relu_output_0']\n",
      "\n",
      "\n",
      "Node name: /Gather\n",
      "Node operation: Gather\n",
      "Node inputs: ['/Relu_output_0', '/Constant_output_0']\n",
      "Node outputs: ['/Gather_output_0']\n",
      "\n",
      "\n",
      "Node name: /Gather_1\n",
      "Node operation: Gather\n",
      "Node inputs: ['/Gather_output_0', '/Constant_output_0']\n",
      "Node outputs: ['/Gather_1_output_0']\n",
      "\n",
      "\n",
      "Node name: /Constant_1\n",
      "Node operation: Constant\n",
      "Node inputs: []\n",
      "Node outputs: ['/Constant_1_output_0']\n",
      "\n",
      "\n",
      "Node name: /Greater\n",
      "Node operation: Greater\n",
      "Node inputs: ['/Gather_1_output_0', '/Constant_1_output_0']\n",
      "Node outputs: ['/Greater_output_0']\n",
      "\n",
      "\n",
      "Node name: /Cast\n",
      "Node operation: Cast\n",
      "Node inputs: ['/Greater_output_0']\n",
      "Node outputs: ['/Cast_output_0']\n",
      "\n",
      "\n",
      "Node name: /If\n",
      "Node operation: If\n",
      "Node inputs: ['/Cast_output_0']\n",
      "Node outputs: ['/If_output_0']\n",
      "\n",
      "\n",
      "Node name: /fc2/Gemm\n",
      "Node operation: Gemm\n",
      "Node inputs: ['/If_output_0', 'fc2.weight', 'fc2.bias']\n",
      "Node outputs: ['x.14']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = onnx.load(\"traced_model.onnx\")\n",
    "for node in model.graph.node:\n",
    "    print(f\"Node name: {node.name}\")  # 节点名称\n",
    "    print(f\"Node operation: {node.op_type}\")  # 节点操作类型\n",
    "    print(f\"Node inputs: {node.input}\")  # 节点输入\n",
    "    print(f\"Node outputs: {node.output}\")  # 节点输出\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时，打印的模型结构里，就存在了 IF 算子，表明现在这个 ONNX 模型可以支持动态操作了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验总结\n",
    "通过本次实验，我们掌握了将 Pytorch 模型转换为 ONNX 格式的基本方法和高级技巧。 torch.onnx.export 提供了一个简单有效的工具来进行模型转换，适用于大多数静态模型。然而，当模型中包含动态操作或自定义操作时，我们需要利用 torch.jit.script 来生成更精确的计算图，从而确保 ONNX 模型的完整性和正确性。最后，我们还需要使用 onnx.checker 进行模型有效性检查的重要性，以发现并解决潜在的问题。\n",
    "\n",
    "除了 PyTorch 以外，许多其他深度学习框架也支持导出模型到 ONNX 格式。例如，TensorFlow 可以利用 tf2onnx 工具来将模型转换成 ONNX 格式。这使得跨平台部署变得更加容易，并且能够利用多种推理引擎的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/onnx/tensorflow-onnx   \n",
    "TensorFlow 转换 ONNX 官方文档"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
