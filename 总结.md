# 考点总结

[历年大学\【真题模拟 1】中文词库分词-1.ipynb] 词库中的最大匹配问题

[历年大学\【真题模拟 2】模型热更新-1.ipynb] 互斥锁、请求体、返回体、json

---

## 文件取用

### txt 文件

**分行取内容**：
extend()保持结构不变 与 append()会直接加入

- extend 拓展保持数据类型不发生改变，append 直接将变量加入其中，可能破坏数据的结构导致出错

[示例查看：历年大学\【真题模拟 7】onnx 模型量化-1.ipynb]

1.构建同义词

```python
diction ={}
with open(filepath, 'r',encoding='utf-8') as f:
    for line in f:
        line.strip() #删除回车，“str”
        words = line.strip().split('r') #删除回车，以','划分,"list"
        for word in words:
            diction[word]=words
return diction
```

2.构建词库

- set 是创建集合，集合的特点内容不重复
- & | - ^ ： 交 并 前有后无的 先并集后减去交集
- set.add() 添加单个元素
- set.upgrade( {"google", "runoob", "apple"} ) 添加多个元素

```python
    dictionary = set()
    with open('words.txt', 'r', encoding='utf-8') as f:
        for line in f:
            word = line.strip()
            dictionary.add(word)
```

### pkl 模型文件：加载与使用

- 一定是 open(modelpath,'rb') 二进制打开为 f，model = pickle.load(f)

  1.pickle：加载与推理

```python
import pickle

current_model = 'svm_1.pkl'
with open(current_model,'rb') as f:
    model = pickle.load(f)

output = model.predict(inputs)

```

2.torch: 加载与推理
情况 1：

- 注意，一定是使用 model.state_dict()

- 一般来说会失败，要求 svm.pkl 的内容与模型的结构完全一致

```python

torch.save(model.state_dict(), 'svm.pkl') # 也可以是'svm.pth'

model = torch.load('svm.pkl')
```

情况 2：

- 注意，一定是使用 model.state_dict()

- 可能会成功，要求 svm.pkl 的内容与模型的结构完全一致，题目中明显没有定义相关模型即废弃

```python

torch.save(model.state_dict(), 'svm.pkl') # 也可以是'svm.pth'

# 从 实例化 到 加载参数 到 load_state_dict(state_dict = )
class model_diy(model.nn)
    def ___init__(self):
        super(model_diy, self).__init__()

    def forward(self, input):

model_object = model_diy()
state_dict = torch.load('svm.pkl')
model_object.load_state_dict(state_dict = state_dict)

# 也可 model_object.load_state_dict(torch.load('svm.pkl'))
```

### csv 文件

### torch 权重

加载 torch 模型权重，并且推理与平均计时

```python
import torch
import torch.utils.benchmark as benchmark
import torchvision.models as modes

def resnet_predict_time(input, model_path, n):
    # 加载 ResNet-18 模型
    resnet_model = models.resnet18()
    resnet_model.load_state_dict(torch.load(model_path))
    resnet_model.eval()
    resnew_bm =benchmark.Timer(stmt='resnet_model(input)',globals={'resnet_model':resnet_model,'input':input})
    # 预测 n 次的平均时间
    resnet_time = resnet_bm.timeit(n).mean
    return resnet_time
```

### onnx 模型

加载.onnx 模型权重，并推理与计时

神奇的是：onnx.load(onnx_model_path)的方式无法推理，同 torch.load(onnx_model_path) 只是模型权重本身无法推理

- onnx: 需要使用 onnxruntime ,onnxruntime.InferenceSession(model_path)

- torch:使用实例化的模型, model.load_state_dict(state_dict=state_dict)

直接加载有什么用：检查

```python
onnx_model = onnx.load(xxxx.onnx")
onnx.checker.check_model(onnx_model)
```

<mark> 标记 </mark>

1 计时器引入

```python
import torch.benchmark as benchmark
import onnxruntime

def reset_predict_time(input, model_path, n):
    ort_session = onnxruntime.InferenceSession(model_path)
    onnx_inputs = {ort_session.get_inputs()[0].name:input.numpy()}

    onnx_bm = benchmark.Timer(stmt='ort_session.run(None,onnx_inputs)',globals={'ort_session':ort_session,'onnx_inputs':onnx_inputs})
    onnx_tm = onnx_bm.timeit(n).mean
    return onnx_tm
```

2 不引入计时器

```python
import pickle
import numpy as np
import onnxruntime as ort

images, labels = pickle.load(open('image_data.pkl', 'rb'))
print(len(images), len(labels))
# 100 100
session = ort.InferenceSession("inference_model.onnx")
output = session.run(None, {'input': images[0]})[0]
print(output.shape, np.argmax(output), labels[0])
# (1, 1000) 1 1

output = session.run(None, {'input': np.concatenate(images[0:10])})[0]
print(output.shape, np.argmax(output, axis=1), labels[0:10])
# (10, 1000) [1 1 1 1 1 1 1 1 1 1] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]

```

## 数学计算实现

### 范数

### 矩阵

### 普通 np 实现，以 ndarray 代图片

1.缩放/插值

```python
old_weight, old_width = image.shape

# 先计算尺寸变化比例
width_scale = new_width/old_width
weight_scale = new_weight/old_weight

# 创新的图像
new_image = np.empty((new_height, new_width),dtype = np.uint8)
# 映射关系实现
for i in range(new_height):
    for j in range(new_width):
        raw_height_postion = int(i / height_scale)
        raw_width_postion = int(j / width_scale)

        new_image[i,j] = image[raw_height_postion,raw_width_postion]
```

2.卷积操作,滤波
![alt text](assets/总结/image.png)

```python
old_height, old_width = image.shape

new_image = np.zeros(image.shape)
edge = int((kernel_size - 1) / 2)

for i in range(old_height):
    for j in range(old_width):

        element = 0
        no_noneNum = 0
        for x in range(-edge, edge + 1, 1):
            for y in range(-edge, edge + 1, 1):
                if(0 <= (i+x) < old_height) and (0 <= (j+y) <old_width):
                    new_element = image[i+x,j+y]
                    no_noneNum += 1
                else:
                    new_element = 0

                element += new_element
        new_image[i,j] = element / no_noneNum

return new_image
```

## 模型定义/转换/训练/选择/量化

### 定义

1.teacher/student

```python

class TeacherModel(nn.model):
    def __init__(self):
        super(TeacherModel, self).__init__():
        self.model = nn.Sequential(
            nn.Linear(784, 512),
            nn.Relu(),
            nn.Linear(512, 256),
            nn.Relu(),
            nn.Linear(256, 128),
            nn.Relu(),
            nn.Linear(256, 10)
            nn.softmax(dim = 1 )
        )

    def forward(self, x):
        return self.model(x)

class StudentModel(nn.Module):
    def __init__(self):
        super(StudentModel, self).__init__()
        self.model = nn.Sequential(
        #TODO
        nn.Linear(784, 512),
            nn.ReLU(),
            nn.Linear(512, 10),
            nn.Softmax(dim=1)
        )

    def forward(self, x):
        return self.model(x)

def train_teacher(model, optimizer, citerion,train_loader):
    model.train()
    for images, labels in train_loader:
        optimizer.zero_grad()
        output = model(images.view(image.size(0),-1))
        loss = citerion(output, labels)

        loss.backard()
        optimizer.step()

def train_student(teacher_model, student_model,optimizer, critertion, distillation_loss,train_loader, model_path='./student_model.pth'):
    teacher_model.eval()
    student.model.train()
    for images,labels in train_loader:

        optimizer.zero_grad()
        teacher_output = teacher_model(images.view(images.size(0), -1)).detach()

        student_output = student_model(images.view(images.size(0), -1))
        loss = criterion(student_output, labels) + 0.5 * distillation_loss(student_output, teacher_output)
        loss.backard()
        optimizer.step()

    torch.save(student_model.state_dict(),model_path)
```

### 转换

1. torchvision.models 库中的 resnet18
   加载 pth state_dict，转化为 onnx

要素：
转换前，先设置为 model.eval() 评估模式
转换时，onnx 的转换是具体的，需要一个 input
so: torch.onnx.export(model,input,out_model_path)

```python
import torchvision
import torchvision.models as models

def onnx_model_transfer(input, input_model_path, out_model_path):
    resnet_model =models.resnet18()
    state_dict = torch.load(input_model_path)
    resnet_model.load_state_dict(state_dict = state_dict)

    # 转换前 要素：转为 eval
    resnet_model.eval()
    torch.onnx.export(resnet_model,input, out_model_path)
```

### 训练

不同于 sklearn 的 fit(X_train, y_train)
torch 模型的训练存在基本规律
梯度置零 optimizer.zero_grad() ， 正向输出 model() ，将输出 output 与 lables 比对得到 loss , loss.backard(),optimizer.step()

```pyhton

model.train()
    for images, labels in train_loader:
        optimizer.zero_grad()
        output = model(images.view(image.size(0),-1))
        loss = citerion(output, labels)

        loss.backard()
        optimizer.step()

```

### 选择

1.sklearn 库，分类模型

- sklearn.tree 单颗树 DecsionClassifier
- sklearn.ensemble 森林 RandomForestClassifier,ExtraTreeClassifier,AdaBoostClassifier
- sklearn.SVM 支持向量机 SVC,NuSVC
- sklearn.neighbors 近邻 KNeighborsClassifier
- sklearn.naive_bayes 朴素贝叶斯 GaussianNB
- sklearn.discriminant_analysis LinearDiscriminantAnalysis
- sklearn.neural_newwork 神经网路 MLPClassifier

```python
import pickle

from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier
from sklearn.svm import SVC, NuSVC
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

SEED = 42

with open('train_data.pkl', 'rb') as f:
    X, y = pickle.load(f)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.5, random_state=SEED)


def init_models():

    classifiers = [
        SVC(random_state=SEED),
        ExtraTreesClassifier(random_state=SEED),
        LinearDiscriminantAnalysis(),
        DecisionTreeClassifier(random_state=SEED),
        KNeighborsClassifier(),
        RandomForestClassifier(random_state=SEED),
        MLPClassifier(random_state=SEED),
        AdaBoostClassifier(random_state=SEED),
        NuSVC(random_state=SEED),
        GaussianNB()
    ]

    return classifiers

def sort_models(models):
    performance = []
    for model in models:
        model.fit(X_train, y_train)
        y_pred = model.predict(x_test)
        acc = accuracy_score(y_test, y_pred)

        performance.append({'model':model,'accuracy':acc})

    sort_model = sort(performance, key = lambda x :x['accuracy', reverse = True])

    return sort_model
```

### 量化

量化 兼 分批次训练

from onnxruntime.quantization import quantize_dynamic, QuantType

```python
import os
import onnxruntime as ort
from flask import Flask, request, jsonify
import numpy as np
import onnx

from onnxruntime.quantization import quantize_dynamic, QuantType

app = Flask(__name__)

if os.path.isfile('inference_model_quantized.onnx'):
    session = ort.InferenceSession("inference_model_quantized.onnx")
else:
    session = ort.InferenceSession("inference_model.onnx")

def quantize_model(model_input='inference_model.onnx', model_output="inference_model_quantized.onnx"):
    #TODO
    quantize_dynamic(model_input=model_input, model_output=model_output,optimize_model=True,weight_type=QuantType.QUInt8)


def inference(data, batch_size):
    input_data = np.array(data).astype(np.float32)
    #TODO
    output = []

    for i in range(0, len(input_data), batch_size):
        batch_data = input_data[i: i+batch_size]
        batch_output = session.run(None,{'input':batch_data})[0]
        output.extend(batch_output.tolist())

    return output

@app.route('/', methods=['POST'])
def main():
    input_data = request.get_json()['input']
    output = inference(input_data, batch_size=10)
    return jsonify({'output': output})


if __name__ == '__main__':
    quantize_model()
    app.run(port=8080)

```

## 部署/后端 flask

### lock()互斥锁

引入 from threading import Lock

- 先实例化，mylock = Lock()
- 在互斥操作前，使用 with mylock:

numpy 转为 list ,tolist()

```python
# 引入
from threading import Lock
import pickle

# 实例化Lock
mylock = Lock()

@app.route('/predict', methods=['POST'])
def predict():
    with model_lock:
        inputs = request.get_json()['input']
        output = model.predict(inputs).tolist()

        return jsonify({'current_model':current_model, 'output': output})

@app.route('/update', methods=['POST'])
def update():
    with model_lock:
        new_model = request.get_json()['model']
        if new_model in ['svm_1.pkl', 'svm_2.pkl', 'svm_3.pkl']:
            global current_model, model
            current_model = new_model
            with open(current_model, 'rb') as f:
                model = pickle.load(f)
            return current_model, 200

        return 'Invalid model', 400

```

### 请求与返回体 json

```python
from falsk import Falsk, request, jsonify

    return jsonify({'current_model':current_model, 'output':output})
    # 化字典为json

    return current_model, 200
    return current_model, 400

```
